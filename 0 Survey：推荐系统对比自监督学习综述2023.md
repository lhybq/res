**0 Survey：推荐系统对比自监督学习综述2023**

[TOC]

---

# 概要
||Survey|
| --- | --- |
| **题目** | Contrastive Self-supervised Learning in Recommender Systems: A Survey |
| **来源** |  |
| **作者** | ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680100784821-aa72981d-8580-4a52-b9dc-1cf8f40f45fd.png#averageHue=%23f2eeea&clientId=ude9324ed-5ff1-4&from=paste&height=100&id=uff9d14c3&originHeight=138&originWidth=598&originalType=binary&ratio=1.375&rotation=0&showTitle=false&size=29350&status=done&style=none&taskId=u2ded1552-ed8a-4a24-9a5b-ad65828783a&title=&width=434.90909090909093) |
| **摘要** | 基于深度学习的推荐系统近年来取得了显著的成功。然而，这些方法通常严重依赖于标记数据(即用户-项目交互)，存在数据稀疏性和冷启动等问题。自监督学习是一种从未标记的数据中提取信息的新兴范式，为解决这些问题提供了见解。其中，对比自监督学习由于其灵活性和良好的性能，近年来已成为基于自监督学习的推荐方法中的一个主要分支。在这项调查中，我们提供了一个最新的和全面的综述，目前对比自我监督学习为基础的推荐方法。首先，我们为这些方法提出了一个统一的框架。然后，我们介绍了基于框架的关键组件的分类，包括视图生成策略、对比任务和对比目标。对于每个组件，我们提供了详细的描述和讨论，以指导选择适当的方法。最后，我们概述了有待解决的问题和未来的研究方向。 |
| **评价** |  |
| **笔记** |  |
| **模型框架** |  |
| **相关资料** |  |


<a name="swzQ4"></a>
# 1.介绍
大多数基于深度学习的方法专注于监督学习场景。推荐模型使用大量的标记数据(即用户-项目交互)进行训练。然而，与交互空间相比，用户-物品交互记录非常稀疏[2,34]。因此，这些方法通常存在数据稀疏性的问题[87]。同时，这些方法容易出现过拟合和泛化误差[50]的问题。<br />自监督学习(SSL[50])作为一种新的学习范式，为解决上述问题提供了新的思路。SSL的基本思想是从数据本身获取可转移的知识，而不需要手动标注标签。这是通过解决辅助任务(称为借口任务)来实现的。然后将获得的知识用于下游任务。SSL由于其高效，被广泛应用于计算机视觉(CV)[11,37,60]、自然语言处理(NLP)[22,54]和图学习[72,89]等多个领域。受SSL在其他领域成功的启发，人们对将SSL应用于推荐领域越来越感兴趣。<br />其中，对比自我监督学习，又称对比学习，已经引起了广泛的关注。CL的目标是最大化正数据对之间的一致性，最小化负数据对之间的一致性。由于其轻量级和有前途的性能，CL已被应用于各种推荐任务，如顺序推荐[63,78,96,117]，通用协同过滤[49,87,105,106,109]等。而且，它最近已经成为基于ssl的推荐的主要分支[110]。具体来说，ACM数字图书馆1中与基于cl的推荐相关的出版物数量超过了与基于ssl的推荐相关的出版物数量的50%。鉴于基于cl的推荐方法的发展趋势，本文对这些方法进行了及时而全面的综述。<br />虽然有一些关于对比学习的综述[39,43]，但主要集中在CV和NLP中的方法上，而没有对基于cl的推荐方法进行综述。然而，由于推荐的唯一性，很难将其他领域已有的基于cl的方法应用到推荐中。具体来说，在CV/NLP中，模型通常处理密集的输入数据，并将每个数据实例视为孤立的。然而，在推荐中，输入数据极其稀疏(如用户/商品的单一热点ID和分类特征)，用户或商品之间存在同质性。此外，推荐系统还存在各种独特的推荐任务，如捆绑推荐和多行为推荐。因此，考虑到推荐与其他领域的差异，有必要对基于cl的推荐方法进行全面的综述。<br />在推荐领域，最相关的调查是[110]。本调查回顾了包含基于cl的方法的基于ssl的推荐方法。与[110]相比，我们的调查有以下差异。首先，我们提出了一个更全面的分类。例如，在提出视图生成策略时，除了[110]介绍的基于数据的增强方法外，我们还介绍了基于模型的增强方法和没有增强的方法。其次，我们讨论了基于cli的推荐方法中关键组件的不同选项的优缺点，可以为这些组件的选择提供指导。这种批判性的讨论没有出现在[110]中。最后，由于基于cl的推荐方法越来越受欢迎，我们提供了一篇更及时的综述，总结了最近发表的未被收录在[110]中的研究。
<a name="hVcle"></a>
## 贡献
1、提出了一个通用框架来统一基于cl的推荐方法。在此基础上，从**视图生成、前置任务(pretext task)和对比目标**三个方面对已有的研究进行了综述。<br />2、我们提供了基于cl的推荐方法的最新和全面的回顾。我们为每个关键组件提供详细的描述和讨论，以指导选择适当的方法。我们还介绍了相关的背景知识，帮助读者更容易理解基于语言的推荐。<br />3、我们确定了现有研究的局限性，并提出了基于cl的推荐的有前途的未来方向，以激发新的研究。
<a name="rdDmv"></a>
## 论文收集
首先采用谷歌Scholar作为主要的搜索引擎来收集相关的论文。然后，我们从顶级会议和期刊中搜索相关工作，如SIGIR, KDD, WWW, AAAI, IJCAI, WSDM, CIKM, NuerIPS, ICML, TKDE, TOIS等。具体来说，我们搜索关键词包括“自我监督”、“对比”、“推荐”、“协同过滤”。为了防止相关工作的遗漏，我们进一步查阅了每篇论文的参考文献。
<a name="Q0QQ3"></a>
## 综述结构
在第2节中，我们将介绍背景知识；在第3节中介绍统一的框架和分类；第4节、第5节和第6节是本文的主要内容，分别介绍了推荐系统中的对比学习。在第7节中，我们将讨论尚未解决的问题和未来的发展方向。最后，我们在第8节进行总结。
<a name="E55oH"></a>
# 2.背景
![88a4cb70efbfb77a595a5f0b75490dac_3_Figure_1_660928112.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680162654632-1035cf09-7bb0-4730-b45b-fb8d7a80e99c.png#averageHue=%23f4f4f3&clientId=uc6894eac-3afd-4&from=ui&id=ub0dbb719&originHeight=1071&originWidth=1053&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=104349&status=done&style=none&taskId=u379e680d-8ebb-437e-8474-60d028247d6&title=)
<a name="Ar6x1"></a>
## 2.1术语
监督学习<br />前置任务&下游任务
<a name="tQKAR"></a>
## 2.2对比学习
对比学习 (CL) 的核心思想是最大化不同视图之间的一致性，**其中一致性通常通过互信息 (MI) 来衡量**。CL的一般流程如图1所示。具体来说，使用视图生成策略生成两个不同的视图。然后，不同视图中的表示由编码器生成，编码器通常由两个视图共享。最后，通过对比损失对模型进行优化，以最大化正对之间的一致性，最小化负对之间的一致性。<br />通常，正例对来自不同视图的相同实例，而负对是来自不同视图的不同实例。形式上，对比自监督学习可以表述为<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163107949-f7404d77-55f8-419b-8169-b48829e718af.png#averageHue=%23f6f4f2&clientId=uc6894eac-3afd-4&from=paste&height=176&id=u6deda44f&originHeight=220&originWidth=1259&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=52113&status=done&style=none&taskId=ud7b1a884-4259-46eb-a55b-e897ce0c406&title=&width=1007.2)
<a name="pCd62"></a>
## 2.3训练策略
目前，基于 CL 的推荐方法采用了两种典型的训练策略：预训练&微调，联合学习。它们的详细工作流程如图2所示。![88a4cb70efbfb77a595a5f0b75490dac_4_Figure_2_660928112.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163187246-d9a84f42-1c36-420f-bc36-d75223ec048a.png#averageHue=%23f5f4f2&clientId=uc6894eac-3afd-4&from=ui&height=500&id=u1f260562&originHeight=657&originWidth=867&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=50671&status=done&style=none&taskId=u5623cad8-4a08-407c-adf7-743fc31fe4b&title=&width=659.4000244140625)

**预训练和微调** ：在这个策略中，模型分两个阶段进行训练。在预训练阶段，编码器𝑓𝜃(·)首先使用对比任务进行预训练。此外，将预训练的参数𝜃𝑖𝑛𝑖𝑡用作编码器𝑓𝜃𝑖𝑛𝑖𝑡(·)的初始化参数。在微调阶段，预训练的编码器 𝑓𝜃𝑖𝑛𝑖𝑡 (·) 使用推荐任务监督的下游解码器 𝑞𝜙 (·) 进行微调。该策略的制定可以定义为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163356450-0cdb810f-1553-4c1f-9ed0-6b671b433d54.png#averageHue=%23faf8f7&clientId=uc6894eac-3afd-4&from=paste&height=166&id=ua5590038&originHeight=208&originWidth=1251&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=34891&status=done&style=none&taskId=uda299b18-3ef8-432a-aecf-48670bd21f6&title=&width=1000.8)<br />**联合学习 (JL)：**在这种策略中，编码器𝑓𝜃 (·) 与预训练任务和下游任务（即推荐任务）联合训练。此外，编码器通常由前置和推荐任务共享。这种策略可以被认为是一种多任务学习策略，其中对比预训练任务是规范推荐任务的辅助任务。损失函数由对比损失和推荐损失组成。学习目标可以形式化为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163507164-36cfe834-1f3e-4915-95a6-1a5fb6a8bdbe.png#averageHue=%23f8f6f5&clientId=uc6894eac-3afd-4&from=paste&height=94&id=u7fa47c82&originHeight=118&originWidth=1253&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=25279&status=done&style=none&taskId=u7f62e1dd-1b22-4896-8c06-ce660aa4fcb&title=&width=1002.4)


<a name="NduBx"></a>
# 3.框架&分类法
本节提出了一个基于 CL 的推荐方法的统一框架。然后从三个角度介绍我们提出的**分类法（taxonomy）**。
<a name="ybHas"></a>
## 3.1统一框架
基于 CL 的方法的一般框架首先执行视图生成策略以获得多个视图，然后通过执行对比预训练任务最大化这些视图中正对的一致性。具体而言：![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163831920-03338dbb-2c4e-4ca8-8d86-65e7961dd48e.png#averageHue=%23f5f3f1&clientId=uc6894eac-3afd-4&from=paste&height=168&id=u071c4a17&originHeight=210&originWidth=1264&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=54740&status=done&style=none&taskId=uefec53b3-628b-42e5-8ab6-13554fa090c&title=&width=1011.2)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163904398-e592da4e-cc10-45a7-a013-9de499a2ded6.png#averageHue=%23f7f5f4&clientId=uc6894eac-3afd-4&from=paste&height=170&id=u641cd826&originHeight=212&originWidth=1259&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=38469&status=done&style=none&taskId=u117d0a45-0cd0-4b26-8159-f1d16714321&title=&width=1007.2)<br />	在训练期间，对比学习是最大化两个视图中正对![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680163987734-623f9f7b-98df-4ba7-b7c2-d275158960d5.png#averageHue=%23ece9e5&clientId=uc6894eac-3afd-4&from=paste&height=14&id=ub16f1023&originHeight=42&originWidth=162&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2788&status=done&style=none&taskId=u7d95ab8d-2c12-499d-9286-37fb302614a&title=&width=55) 表示之间的一致性。此外，互信息 ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680164000518-741d4c15-f7cf-4690-885a-0be96d92c558.png#averageHue=%23ece9e5&clientId=uc6894eac-3afd-4&from=paste&height=25&id=u8d80d134&originHeight=42&originWidth=162&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2788&status=done&style=none&taskId=u23df5108-5bfb-48df-bb0a-b928dc8cbc7&title=&width=97.5999984741211) 通常用于衡量一致性。对比目标可以定义为：![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680164012294-4941e74e-d1b1-4ffc-9c84-67345b2b192c.png#averageHue=%23f2f0ee&clientId=uc6894eac-3afd-4&from=paste&height=41&id=u607ad2df&originHeight=80&originWidth=368&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7266&status=done&style=none&taskId=u02a6a59a-f9d3-4ef3-8c5c-c357eee81c0&title=&width=189.40000915527344)<br />其中𝜆 ∈ {0, 1}，如果计算h𝑖和h𝑗之间的互信息，则𝜆 = 1，否则𝜆 = 0。<br />由于很难直接计算互信息，因此通常使用互信息估计器。可以根据![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680164115758-8aab37b2-183f-4918-a088-3e15e733a585.png#averageHue=%23ede9e3&clientId=uc6894eac-3afd-4&from=paste&height=24&id=uf14f8d5f&originHeight=30&originWidth=71&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1380&status=done&style=none&taskId=ud09bb3d4-d48f-463a-9af7-77ffa46c05a&title=&width=56.8)（即前置解码器）估计互信息。此外，投影[15] 可以选择性地应用于![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680164207026-1f98357a-f09f-4c3d-aaa4-bf87cde6abc2.png#averageHue=%23ede9e5&clientId=uc6894eac-3afd-4&from=paste&height=34&id=u2e1a5651&originHeight=43&originWidth=100&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2033&status=done&style=none&taskId=u63acfd5a-89be-464d-80bc-7810e49d335&title=&width=80)，定义为：![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680164216465-5d620844-dd83-4508-8b66-8c6ffb6e8046.png#averageHue=%23f5f3f1&clientId=uc6894eac-3afd-4&from=paste&height=38&id=u59e6ca05&originHeight=47&originWidth=351&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=4344&status=done&style=none&taskId=u7d617ef9-1961-4762-964b-4638d8007a1&title=&width=280.8)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680501336377-88b0e49d-ee73-46aa-9823-37e88545f647.png#averageHue=%23f4f2f0&clientId=u6cbeaf16-728a-4&from=paste&height=286&id=u68d6b2d5&originHeight=357&originWidth=1278&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=85914&status=done&style=none&taskId=ue3a538a5-d82c-4023-baac-7eb8665feee&title=&width=1022.4)
<a name="hzfIj"></a>
## 3.2方法分类
对比学习方法的不同在于三个关键组成部分：**视图生成策略、前置任务(pretext task)、对比目标。**通过指定这些方法可以确定基于CL等推荐方法。但是编码器![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680501916606-a1b1cc30-51ed-4a01-8fe2-ac6d50653c18.png#averageHue=%23f3eee8&clientId=u6cbeaf16-728a-4&from=paste&height=25&id=uaaf90e5b&originHeight=31&originWidth=51&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1100&status=done&style=none&taskId=u4c5f7a69-ad16-4f7b-872d-24031f5c15b&title=&width=40.8)这里不在考虑之中，因为它与具体的推荐任务有关，而不是基于CL推荐的重点。<br />基于此，本文基于这三大组件对CL方法进行分类，如下图为基于对比学习的推荐分类，下表为基于对比学习的推荐系统代表研究成果：<br />![88a4cb70efbfb77a595a5f0b75490dac_6_Figure_3_-347760707.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680503207030-00b6951a-5b12-4b6e-8825-c1d7129ce790.png#averageHue=%23ebf3e9&clientId=u6cbeaf16-728a-4&from=ui&height=440&id=u049b2e2f&originHeight=840&originWidth=1056&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=67802&status=done&style=none&taskId=u0f28d109-dd7f-457d-8160-98d1b5432c0&title=&width=553.4000244140625)<br />_表2：基于 CL 的推荐方法的总结，“L-L”、“C-C”和“G-G”分别表示局部-局部、上下文-上下文和全局-全局，“CF”表示协同过滤，“KG”表示知识图_<br />![88a4cb70efbfb77a595a5f0b75490dac_7_Table_2_329735194.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680505094122-b24c5d8f-00d1-4d77-81ee-822cae2aa550.png#averageHue=%23ededed&clientId=u6cbeaf16-728a-4&from=ui&id=u8848f607&originHeight=1653&originWidth=1119&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=476320&status=done&style=none&taskId=uf3783157-2904-4864-8327-1bfaa5d4882&title=)
<a name="YzLXG"></a>
### 分类依据：
**视图生成**设计如何生成数据视图。根据是否需要增强，我们将视图生成策略分为增强视图生成和不增强视图生成。<br />**前置任务**是如何获取监督信号的设计。根据被对比实例的规模，我们将前置任务分为同尺度对比和跨尺度对比。<br />**对比目的**设计如何测量互信息。根据是否提供互信息下界估计，我们将对比目标分为有界目标和无界目标。
注意，这些组件的选择取决于输入数据和下游任务的特征。例如，基于序列的增强方法可能不适合图数据。对于序列推荐，前置任务通常比较序列表示，因为主要目标是学习好的序列表示。<br />值得注意的是，组件的选择并不是完全独立的。虽然相同的前置任务可以用不同的视图生成策略或对比目标来完成，但有些可能是无效的。例如，当前置任务旨在为项目的顺序关系建模时，基于特征的增强方法可能不有效。因此，**在设计基于cl的推荐方法时，我们可以先根据具体的推荐任务设计前置任务，然后选择相应的视图生成策略和对比目标。**
<a name="tH3d7"></a>
# 4.视图生成
最近在其他领域的研究[45,70,80]表明，对比学习在很大程度上依赖于视图生成，因为生成多个视图有助于模型探索更丰富的底层语义信息。在实践中，如果自然存在多个数据视图，例如交互视图和社交视图网络在社会推荐中，前置任务可以直接在这些视图上执行。另外，在很多场景下，并没有多个视图，因此需要对原始数据进行增强，生成数据视图[11,22,28]。因此，我们将现有的视图生成策略分为带增强和不带增强的视图生成。<br />![88a4cb70efbfb77a595a5f0b75490dac_8_Figure_4_1333891791.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680505300493-42ed3980-0c2e-4281-ba7a-67a5c923a5ae.png#averageHue=%23f8f6f6&clientId=u6cbeaf16-728a-4&from=ui&height=277&id=ucf8bd54c&originHeight=408&originWidth=642&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=26360&status=done&style=none&taskId=ua8d4d64c-e324-427c-b1c4-14563c9c46d&title=&width=436)<br />_基于图的增强：图扰动，原始图，子图抽样，图扩散_
<a name="nzzAd"></a>
## 4.1有增强
增强策略可以分为基于数据增强和基于模型的增强。前者根据数据生成视图，而后者基于模型。
<a name="Y24Tu"></a>
### 4.1.1基于数据的增强
基于要增强的数据类型，我们将基于数据增强分为**基于图的增强**、**基于序列的增强**和**基于特征的增强**。
<a name="PnyP6"></a>
#### A.基于图的增强：
该策略如上图所示，在（例如交互图和社交图）上执行增强以生成多个视图。但是，由于图中节点属性的增强类似于基于特征的增强，在这个子类别下，我们只呈现图结构的增强（如上图所示）。形式上，给定一个图 ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680506585097-28204c04-6e36-45f4-9434-9035904c9f77.png#averageHue=%23e7ece3&clientId=u6cbeaf16-728a-4&from=paste&height=23&id=udf07cade&originHeight=35&originWidth=151&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=3448&status=done&style=none&taskId=uf128d38f-2b1b-4503-a2e9-5cf5a0b1f83&title=&width=99.80000305175781)，基于图的增强变换 ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680506622745-9238d92d-85ec-4d31-a58b-29c4e12ff844.png#averageHue=%23e7ece3&clientId=u6cbeaf16-728a-4&from=paste&height=5&id=ua099525f&originHeight=35&originWidth=151&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=3448&status=done&style=none&taskId=u7349d23b-a9b0-4193-8166-c83a933ea20&title=&width=23) 的邻接矩阵 A，即 ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680506654405-aba92a94-1ecb-4869-ad27-877d47315895.png#averageHue=%23e7ece3&clientId=u6cbeaf16-728a-4&from=paste&height=20&id=u79e78536&originHeight=34&originWidth=141&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2557&status=done&style=none&taskId=udb9c4b3c-6368-41a8-889c-b9e9ad48e74&title=&width=84.80000305175781)。<br />**边缘扰动**。该策略[27，44，46，53，56，75，76，87，91，100，101]通过随机添加或删除边来生成图形视图。它可以定义为：![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680506708971-bb0da66c-82eb-4f39-9d94-c5ecbfdc1323.png#averageHue=%23f2f0ef&clientId=u6cbeaf16-728a-4&from=paste&height=28&id=u1dcbc2a4&originHeight=43&originWidth=448&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=4163&status=done&style=none&taskId=u91570393-3170-4081-a977-618f68afa92&title=&width=287.3999938964844)<br />其中 L 是位置矩阵。如果 L𝑖𝑗 = 1，则𝑖 和 𝑗 之间的边将受到扰动。具体来说，如果A𝑖𝑗 = 1，则L𝑖𝑗 = 1，则将丢弃𝑖 和𝑗 之间的边。如果 A𝑖𝑗 = 0，则 L𝑖𝑗 = 1，将在 𝑖 和 𝑗 之间添加一条边。L 可以随机抽样 [87, 100 ] 或手动设置。此外，L 也可以自适应地计算 [38, 40] 以保持重要边缘，同时扰乱可能不重要的边缘。<br />**图扩散。** 图扩散[55,13]通过在节点之间创建新的边，将全局信息合并到原始图中。它可以表述为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680507779288-62f42dd2-c34c-4bd6-90b1-194d527b7d19.png#averageHue=%23f4f3f1&clientId=u6cbeaf16-728a-4&from=paste&height=50&id=u242c49a0&originHeight=89&originWidth=226&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=4740&status=done&style=none&taskId=u73332422-63ac-4ad4-9946-adb644a14bc&title=&width=126.80000305175781)<br />其中![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680509568246-b26cee9e-dea7-4bbf-b953-7d8ab01e3a9a.png#averageHue=%23eeeae5&clientId=u6cbeaf16-728a-4&from=paste&height=33&id=ub9af0603&originHeight=41&originWidth=41&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1054&status=done&style=none&taskId=u7c90a1a5-bc9d-4a79-b554-a77483ae97f&title=&width=32.8)是加权系数，T 表示广义转移矩阵。例如SMIN [55] 生成子结构感知的相邻矩阵并将其注入到用户-项目交互图中。<br />**子图采样。** 该策略对节点子集和相应的边进行采样以生成子图作为数据视图。<br />现有方法通常通过均匀采样和自我网络采样和基于知识的采样来获得节点子集![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680510212506-7d195973-ef8c-4c7f-bc1e-35d8bfc15e46.png#averageHue=%23e7e3de&clientId=u6cbeaf16-728a-4&from=paste&height=17&id=ub4498055&originHeight=27&originWidth=44&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=772&status=done&style=none&taskId=u3f9b68fa-8b9d-41fe-9cf2-2b077df89dd&title=&width=27.200000762939453)。均匀采样 [ 27, 31, 64, 87, 112 ] 统一采样一定部分节点和相应的边以增强视图。节点丢失属于均匀采样。例如，SGL [13] 随机丢弃一部分节点，表示为 V𝑑。因此，采样的节点子集可以通过![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680510780564-ab3cc907-0bf8-4193-b975-dd7bdf369994.png#averageHue=%23f0eeec&clientId=u6cbeaf16-728a-4&from=paste&height=18&id=ufab69968&originHeight=37&originWidth=185&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1827&status=done&style=none&taskId=ueb886f48-3627-4469-bce4-f369f66460f&title=&width=91) 获得。<br />**去网络采样** [9 ] 对图中每个节点的 𝐿 跳邻居进行采样，也称为 𝐿-ego 网络。因此，节点子集可以表示为 ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680510868932-305a11f4-2dc3-410a-9f2d-a7ca0e79bde8.png#averageHue=%23ede9e5&clientId=u6cbeaf16-728a-4&from=paste&height=19&id=uf3d3cf71&originHeight=31&originWidth=262&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=3875&status=done&style=none&taskId=u95549eea-2b0e-494c-bcff-00a7a1ebe33&title=&width=164.60000610351562)，其中 𝑑 (𝑣𝑖, 𝑣 ) 是节点 𝑖 和 𝑗 之间的最短距离。<br />**基于知识的采样** [76, 108] 在采样子图时结合了领域知识。例如MHCN [108 ] 基于底层语义设计了三种类型的三角形图案。Motifs 指定了高阶关系，例如“有一个相互的朋友”。
<a name="YGINW"></a>
#### B.基于序列的增强：
基于序列的增强有如下类别，详细介绍略；<br />![88a4cb70efbfb77a595a5f0b75490dac_9_Figure_5_-190530169.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680511052260-eae5f6ed-4107-4c5a-8c1c-2b3a68962234.png#averageHue=%23f9f9f9&clientId=u6cbeaf16-728a-4&from=ui&id=u4923f1be&originHeight=402&originWidth=948&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=37090&status=done&style=none&taskId=u364ac799-eefc-4d91-9c02-27007544e9f&title=)
<a name="tzzSQ"></a>
#### B.基于特征的增强：
基于特征的增强（如下图所示）对特征向量执行增强，特征向量可以是分类特征或特征表示（例如嵌入）。给定特征矩阵 X，增强视图表示为![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680511199684-155a0f19-3e80-41c9-9a7e-2ca3b4dfb68c.png#averageHue=%23ebe7e4&clientId=u6cbeaf16-728a-4&from=paste&height=21&id=u3748135d&originHeight=37&originWidth=132&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2014&status=done&style=none&taskId=ubcff68f3-c331-4b3c-8b8e-85f4a2316cb&title=&width=75)。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680511980565-20ebe6d2-46da-464a-9db9-b37d30dfe28e.png#averageHue=%23efeae9&clientId=u6cbeaf16-728a-4&from=paste&height=131&id=ue10abd6c&originHeight=223&originWidth=715&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=11044&status=done&style=none&taskId=uc13dc6df-ae50-4c0d-b809-74e67c1a2f5&title=&width=420)<br />**特征丢弃**。特征丢弃 (masking) [58, 74 , 104 ] 掩盖/丢弃部分特征，表示为![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680511283577-ca7ddace-1585-4369-8cc7-183e8b5bdc5d.png#averageHue=%23f0edeb&clientId=u6cbeaf16-728a-4&from=paste&height=22&id=u49a9d670&originHeight=39&originWidth=268&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2945&status=done&style=none&taskId=u67911e35-a69a-4e1c-8645-8bcd90a502a&title=&width=153.40000915527344)，其中 L 是表示掩码位置的掩码矩阵。如果i的第j特征被掩蔽/丢弃，则Lij=1，否则Lij=0。与边缘扰动类似，L可以均匀采样或手动分配。◦ 是 Hadamard积。<br />**特征打乱**。特征变换[6,93,101,108]按行或列扰动特征矩阵。它可以表述为:![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680511830627-4198eaf8-c4c4-41fb-8aaf-d8d33c93c98c.png#averageHue=%23ede9e6&clientId=u6cbeaf16-728a-4&from=paste&height=25&id=uc907b424&originHeight=38&originWidth=276&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=3793&status=done&style=none&taskId=u907c4686-4f9a-425c-9bd0-7ea7717aac0&title=&width=180.8000030517578)![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680511874666-a7183e6f-6203-493e-8ec7-25af7e70056f.png#averageHue=%23ede9e5&clientId=u6cbeaf16-728a-4&from=paste&height=30&id=u79b78614&originHeight=38&originWidth=1194&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=12673&status=done&style=none&taskId=u3cf4ac05-29c3-4106-ac8e-65daeadb097&title=&width=955.2)
<a name="SQeBC"></a>
### 4.1.2基于模型的增强
基于模型的增强(如下图所示)通过扰动模型(即编码器)生成视图，可以表述为:![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512030073-a252d4ce-9e15-4f24-8acf-18dacd566db8.png#averageHue=%23efece8&clientId=u6cbeaf16-728a-4&from=paste&height=25&id=u65f1a1c3&originHeight=42&originWidth=335&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=4639&status=done&style=none&taskId=ue8e4d4e8-abb2-4304-abc2-c05f3d30824&title=&width=202)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512063659-489615d5-8955-4190-9d35-9380df81d4f2.png#averageHue=%23eeeae7&clientId=u6cbeaf16-728a-4&from=paste&height=32&id=u7e472b7f&originHeight=40&originWidth=1190&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=13212&status=done&style=none&taskId=u7b996949-d8e1-4756-813b-d9115dca26a&title=&width=952)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512333401-308f557d-5145-4230-b4c8-a26ebdf5a195.png#averageHue=%23dadbc0&clientId=u6cbeaf16-728a-4&from=paste&height=261&id=u4f331bb6&originHeight=326&originWidth=1238&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=54777&status=done&style=none&taskId=ue97d19d7-011e-486b-a717-7a035edc350&title=&width=990.4)<br />**消息丢弃。** 该策略[20,51,56,63,74]以一定的dropout ratio[22]，随机丢弃层中的神经元。然后通过应用不同的dropout掩码，可以使用相同的输入数据获得多个视图。例如，DuoRec[63]在基于transformer的模型上应用了两种不同的dropout mask来生成两种不同的视图。<br />**嵌入噪声**。该策略[105,106,109]通过在原始嵌入中添加不同的噪声来生成不同的视图。与基于特征的增强只会干扰输入嵌入或最终表示不同，该策略在编码器的不同层向嵌入添加噪声。它可以表述为:![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512479307-b8cf1999-96f6-4d3d-b02f-5b3920ce9775.png#averageHue=%23f0eeec&clientId=u6cbeaf16-728a-4&from=paste&height=22&id=u9191a6ca&originHeight=43&originWidth=166&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1924&status=done&style=none&taskId=u8b0ed65a-a598-4bd8-8734-1e81714e83a&title=&width=85.80000305175781)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512554264-896ee607-7369-4aa1-b906-9e2056391125.png#averageHue=%23f0edea&clientId=u6cbeaf16-728a-4&from=paste&height=114&id=u78967495&originHeight=143&originWidth=1265&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=48046&status=done&style=none&taskId=u48e838a3-7522-4be2-abc3-b3c80e8f741&title=&width=1012)<br />**参数噪声。** 该策略[90]将噪声添加到编码器的参数中，其表述为:![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512657678-6de73314-5be6-4b62-b462-67be690703cc.png#averageHue=%23f0ede9&clientId=u6cbeaf16-728a-4&from=paste&height=18&id=u76e76390&originHeight=36&originWidth=167&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2193&status=done&style=none&taskId=uab1dfced-5e81-4e00-80e9-2f69d129040&title=&width=84)![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680512687069-97dd5235-fe6e-47c8-9f9f-6286f770e3fc.png#averageHue=%23ece8e3&clientId=u6cbeaf16-728a-4&from=paste&height=58&id=u784cc354&originHeight=72&originWidth=1256&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=25727&status=done&style=none&taskId=u7cb13d78-3194-4b03-9936-1fbd4de87fc&title=&width=1004.8)<br />**体系结构扰动。** 与上述策略对模型中可学习参数的扰动不同，一些工作通过改变模型架构产生不同的视图。例如，SRMA[51]提出了层Dropout和编码器互补。具体来说，在训练过程中，Layer dropoutt会随机丢弃模型中的一部分图层，从而实现浅特征和深特征之间的对比学习。编码器互补使用预训练的编码器来生成表示。这些表示与原始编码器生成的表示相结合，进行对比学习。MA-GCL[23]提出通过改变传播和transformer的数量与排列来扰动图神经网络(GNN)编码器的结构。
<a name="XvQep"></a>
## 4.2不使用增强
**对比学习的关键思想是最大化不同视图之间的一致性。因此如果自然存在多个视图，则可以直接对比这些视图，而无需额外的增强。** 例如，在跨域推荐中，两个域可以被认为是两个视图。因此，CCDR[95]和ML-SAT[116]等方法直接对这些领域进行对比学习。对于基于知识图的推荐，一些方法[75]使用知识图作为对比视图。对于多行为推荐，可以根据辅助行为数据构建视图。例如，S-MBRec [25] 将每种类型的行为视为视图。具体来说，HMG-CR [99] 基于使用辅助行为与目标行为购买之间的距离构建的超元路径构建不同的超元图。在捆绑推荐中，还可以对比用户-项目交互和用户-捆绑交互[56]。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680513252203-2c664a4b-0f0d-4e66-b629-ad7f36ddb5d7.png#averageHue=%23f3f2f1&clientId=u6cbeaf16-728a-4&from=paste&height=198&id=u303898d6&originHeight=368&originWidth=1080&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=51699&status=done&style=none&taskId=u5e561677-2855-439a-8d94-413ca60cd0c&title=&width=581.4000244140625)
<a name="ZBgqB"></a>
## 4.3总结
上表显示了不同视图生成策略之间的比较。具体而言，现有的基于cl的推荐方法大多采用基于数据的增强策略，因为它们易于实现。然而，基于数据的增强通常是通过人工试错来选择的，这大大限制了这些方法的通用性。此外，一些数据增强破坏了原始数据的语义信息，可能会损害推荐性能[109]。<br />无增强的策略不需要试错。此外，这些策略通常使用领域知识来构建辅助视图，以保留数据的语义。然而，领域知识是昂贵的，不能应用到其他领域。此外由于在模型训练期间视图是固定的，没有增强的策略缺乏引入有助于学习噪声不变表示的随机性。<br />与其他策略相比，基于模型的增强具有更好的泛化性，因为它们在不考虑原始数据的情况下改变学习的表示。尽管基于模型的增强不需要试错和领域知识，但消息/层的退出率等设置仍然需要手动调优。这在一定程度上限制了它们的普遍性。此外，设计架构扰动具有挑战性。<br />此外，许多工作[20,56,74,81]采用了结合多种视图生成策略的混合方法。通过这样做，不同策略的优势可以结合起来。然而，一些缺点可能仍然存在。例如，将没有增强的策略与基于数据的增强相结合可能有助于引入随机性，但基于数据的增强仍然需要手动试错。**此外，如何为特定的推荐任务选择最优的视图生成策略还不清楚。**
<a name="Kqprs"></a>
# 5.前置任务
对比学习的目标是最大化正对(即具有相同语义信息的实例)之间的互信息，最小化负对(即具有不相关语义信息的实例)之间的互信息。根据实例的规模，我们将现有的对比前置任务分为**同尺度对比和跨尺度对比两类**。具体来说，有三种对比尺度:**局部、上下文和全局。**<br />局部尺度通常表示输入数据的最小粒度，而全局尺度表示最大粒度。例如，在图(序列)数据中，局部尺度代表节点(项/特征)，全局尺度代表整个图(序列)。上下文尺度介于局部尺度和全局尺度之间，表示子图(子序列)。
<a name="nW7Xb"></a>
## 5.1相同尺度对比
根据对比尺度的不同，同尺度对比(如图8所示)又可分为局部-局部对比(L-L)、上下文-上下文对比(C-C)和全局-全局对比(G-G)三种类型。考虑到推荐任务的独特性，我们提出了基于其推荐任务的现有方法。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680526740495-4b5dc818-84af-4503-a76d-af32ce99dc82.png#averageHue=%23f3f1ee&clientId=u6cbeaf16-728a-4&from=paste&height=218&id=u4e6568e4&originHeight=432&originWidth=537&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=36121&status=done&style=none&taskId=u4bcada6f-0e2e-46af-8df7-17e20b32ac8&title=&width=271.6000061035156)
<a name="IvUad"></a>
### 5.1.1L-L对比
这类方法主要区分局部表示(即用户/项的表示)，可以表述为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680526996394-ddb409c6-bc01-4f12-bd9b-ccb56d500406.png#averageHue=%23f5f3f0&clientId=u6cbeaf16-728a-4&from=paste&height=43&id=uea176aef&originHeight=62&originWidth=440&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7685&status=done&style=none&taskId=ua176258d-a550-41ef-b3d5-b8db242b523&title=&width=304)<br />hi和hj分别是实例i和j在不同视图的表示，这些表示由不同视图共享的编码器![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680527313580-de09a205-793d-4890-b216-e2e5680b41b1.png#averageHue=%23ece7e1&clientId=u6cbeaf16-728a-4&from=paste&height=23&id=u5425916a&originHeight=33&originWidth=58&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1402&status=done&style=none&taskId=u15c68ea7-21d5-448f-b4cd-6c94c7d3538&title=&width=40.39999961853027)生成。<br />**Graph-based Collaborative Filtering：**根据对比图的类型，方法可以分为**基于用户-物品图的对比和基于不同图的对比。**
<a name="UFqgE"></a>
#### （i）用户-物品图对比。
由于只存在一个图，因此该类下的方法应该对用户-项目交互图进行扩充，以生成不同的视图。<br />SGL[87]首次将对比学习应用于基于图的推荐。给定一个用户-物品交互图![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528538643-e858cbec-3568-4b38-b0d0-3c79aa78fc0b.png#averageHue=%23d9d3cd&clientId=u6cbeaf16-728a-4&from=paste&height=23&id=ufe47c63d&originHeight=33&originWidth=26&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=790&status=done&style=none&taskId=u6ede7015-b0e5-4b81-a260-cb40de33f37&title=&width=17.80000114440918)，它首先生成两个不同的图视图![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528561353-ff3c63e6-5806-4f5e-a739-aaacc8193711.png#averageHue=%23edeae6&clientId=u6cbeaf16-728a-4&from=paste&height=24&id=u406c7078&originHeight=39&originWidth=406&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=5431&status=done&style=none&taskId=u553d5ba7-253a-4e38-90fd-ca1ba71b237&title=&width=250.8000030517578)。![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528589215-e5c88ce8-60d5-4893-afe6-3fb5e9a6fe1a.png#averageHue=%23e3dfdb&clientId=u6cbeaf16-728a-4&from=paste&height=20&id=u5718b8c4&originHeight=27&originWidth=26&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=591&status=done&style=none&taskId=u659d73c7-550f-4efa-9f47-5891937010b&title=&width=18.80000114440918)是视图生成策略。此外，它利用了三种基于数据的增强，包括**节点dropout、边缘dropout**和**随机游走**(在每一层应用边缘dropout)。<br />然后，利用LightGCN[35]作为图形编码器![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528656302-eb787e47-b814-44db-a257-f2d86e1fffea.png#averageHue=%23ece7e1&clientId=u6cbeaf16-728a-4&from=paste&height=21&id=u15f2f547&originHeight=33&originWidth=58&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1402&status=done&style=none&taskId=uaaeef1d3-cbdd-4ab7-90b5-b19e4f3cf57&title=&width=37.400001525878906)生成节点表示<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528684024-b5279fa6-fba5-4358-a82f-5e68b66f1f0c.png#averageHue=%23eceae8&clientId=u6cbeaf16-728a-4&from=paste&height=25&id=u2474e331&originHeight=35&originWidth=94&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1257&status=done&style=none&taskId=u793e1e3a-7b2a-4883-9173-2e667d69dac&title=&width=67.20000457763672)![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528702052-f82f5c12-36f6-479a-a1bf-180f9f1673ec.png#averageHue=%23ece8e4&clientId=u6cbeaf16-728a-4&from=paste&height=27&id=u40c33f82&originHeight=38&originWidth=369&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=5547&status=done&style=none&taskId=uc7389140-3ad2-4529-99c8-079c06e6281&title=&width=261.20001220703125)。然后执行节点自识别任务。具体来说，它使同一节点(即正对)在不同视图中的表示相似，而使不同节点(即负对)在不同视图中的表示不同。用户方的对比损失可表示为（物品方的损失也可以类似定义）:<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680528949015-21b4b459-f2d5-4b5f-b3ac-1479c6a183f3.png#averageHue=%23f2f0ee&clientId=u6cbeaf16-728a-4&from=paste&height=53&id=u9db1f1fd&originHeight=97&originWidth=527&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=14164&status=done&style=none&taskId=u67ff5da8-e4c9-44a2-a9f0-ab91163b5d7&title=&width=288.6000061035156)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680532485705-dfcc445b-77a7-47bf-821c-e3ebd13c96c7.png#averageHue=%23efece8&clientId=u6cbeaf16-728a-4&from=paste&height=65&id=u1e343eee&originHeight=81&originWidth=1269&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=31934&status=done&style=none&taskId=u1168114f-5e93-4688-87be-a024e68c70b&title=&width=1015.2)<br />为了提高效率，SGL采用批内负采样，只考虑同批B中的不同节点，而不是将其他所有节点都作为负样本。因此Neg被定义为<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680532587254-0bc9179f-321a-48db-82f4-2a3a495ae241.png#averageHue=%23f6f4f2&clientId=u6cbeaf16-728a-4&from=paste&height=51&id=u6c9e217b&originHeight=82&originWidth=430&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=8766&status=done&style=none&taskId=u0f3b29ba-3dd8-48c8-aabd-1b93ae83997&title=&width=265)<br />其中hv和hu是视图间负对。因此对比损失即为![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680532741773-5a0df351-a3bb-4edd-a5d4-3ef45926ea8b.png#averageHue=%23ece9e5&clientId=u6cbeaf16-728a-4&from=paste&height=24&id=u3c912d79&originHeight=36&originWidth=272&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=4485&status=done&style=none&taskId=ua6c75f5e-cb52-4c49-bce0-e0911d58928&title=&width=180.60000610351562)，最后，SGL采用联合学习策略对对比损失和推荐损失进行优化。<br />在SGL框架的基础上，提出了若干工作。与SGL的主要区别在于视图生成策略。DCL[53]perturbs the edges in 𝐿-ego net of each node to obtain views。GDCL[113]使用图扩散生成新的图视图。此外，构造视图内的负对，上式可重写为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680532864398-cbd085b0-43b9-4aa2-8bb8-8c2f733c83a3.png#averageHue=%23f6f4f2&clientId=u6cbeaf16-728a-4&from=paste&height=50&id=u9f628ecf&originHeight=81&originWidth=642&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=11651&status=done&style=none&taskId=u5b488064-3db5-433f-a1fd-ac8ed38ba2f&title=&width=395.6000061035156)<br />SimGCL[109]、XSimGCL[106]和RocSE[105]通过在节点表示中添加均匀噪声来生成视图。此外，为了降低计算复杂度，XSimGCL[106] 将最后一层对比度替换为跨层对比。它只利用一个 GNN 编码器并对比不同层的嵌入。LightGCL[7]提出了一种**基于奇异值分解(SVD)的图增强策略**来有效地提取全局协作信号。具体来说，SVD 首先对邻接矩阵执行。然后，将奇异值列表截断以保留最大的值，并使用截断矩阵重构邻接矩阵。在重构图和原始图之间执行节点对比学习。RGCL[64]还执行边缘对比学习。它最大化评论表示和相应的交互表示之间的 MI。具体来说，通过将用户和项目表示输入 MLP 来获得交互表示。
<a name="GhSaV"></a>
#### （ii）不同图对比。
除了用户-项目交互图之外，一些工作还使用交互数据构建其他图。即视图通常是在没有增强的情况下生成的。<br />MCLSR [82] 基于交互序列构建三个图，包括用户项目关系图、项目-项目关系图和用户-用户关系图。HCAF [ 91] 构建了两个视图，包括用户-项目交互图和可学习的超图。与 SGL 相同的节点识别区分任务在 MCLSR 和 HCAF 中执行。	SGCCL [44 ] 构建用户-用户图 G𝑢𝑢 和项目-项目图 G𝑖𝑖，并执行边缘/特征丢失来增强它们。节点识别区分是在 增强后的G𝑢𝑢 和 G𝑖𝑖 上进行的。	MPT [31] 扩展了执行重建任务的 PT-GNN [32]，只能对内部相关性进行建模。它利用对比任务来捕获数据中的相互关联。具体来说，它对每个用户的子图/路径进行采样。节点丢失/替换用于增强子图/路径。在增强子图/路径中相同用户的表示之间的**MI**被最大化。<br />**基于知识图的推荐。**除了交互数据外，知识图（KG）也被用于基于CL的推荐，因为它可以带来丰富的语义信息。<br />通常，使用KG的基于CL的推荐方法通过手动设计生成视图。MCLK[120]构建了三个视图，包括用户-项目图$G_{ui}$, 项目-实体图$G_{ie}$和用户-项目-实体图$G_{uie}$. 它最大化分别在$G_{ui}$和$G_{uie}$中用户表示$h_u^{(ui)}$, $h_u^{(uie)}$ 之间的MI，以及最大化分别在$G_{ui}$和$G_{ie}$中用户表示$h_i^{(ui)}$, $h_i^{(ie)}$ 之间的$MI$. 此外，它为每个项目生成一个新的表示![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680593789701-2c93247a-633e-44c6-a07a-bbdd73d1d3b6.png#averageHue=%23efece8&clientId=u6cbeaf16-728a-4&from=paste&height=25&id=u699b6056&originHeight=45&originWidth=200&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=2964&status=done&style=none&taskId=ua043a6e2-63ad-48a6-a51f-6f714dde1f2&title=&width=112)，其中||是串联操作（concatenation operation，将新向量拼接到原来的之后，对应维数增加），然后通过执行节点自我识别区分来最大化$h_i'$和$h_i^{(uie)}$之间的MI。KACL[75]最大化增强用户-项目图中同一项的表示与增强知识图之间的MI。此外，增强图是通过自动删除不重要的边来生成的。<br />知识图KG也可以用于指导不同的用户用户-项目视图的生成，例如KGCL[100]在知识图上执行随机增强，以生成两个不同视图 ...... 然后使用知识引导的数据增强增强用户-项目交互图 ...... 此外，KGCL同时执行视图间和视图内对比。<br />**基于多行为的推荐。**为了提高用户意图建模，多行为推荐方法结合了多种类型的用户行为数据，可用于构建对比视图。S-MBRec [25] 采用**星形风格**的对比任务，即它只在目标行为（通常是购买）和每个辅助行为之间执行对比学习。它根据与目标行为的相似性采样正样本。相似度由逐点互信息 [102] 计算。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680600421849-d19727a0-9b8d-407f-b63e-c33147063724.png#averageHue=%23f6f5f3&clientId=u117cbb02-c405-4&from=paste&height=148&id=ue64dba21&originHeight=247&originWidth=372&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=16399&status=done&style=none&taskId=u307b3c2e-2160-4280-849f-491ad166d5e&title=&width=223.60000610351562)<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680600521118-d7644c42-e151-42a1-99f5-2d33e3fda6ca.png#averageHue=%23e9e4df&clientId=u117cbb02-c405-4&from=paste&height=20&id=uf317a983&originHeight=33&originWidth=61&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=1408&status=done&style=none&taskId=u793ee507-11b4-412b-be71-42d7ca4ad7e&title=&width=36.79999923706055)是与用户u有交互的物品集合。![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680600596739-be497d8a-f961-4de1-8ce3-10573ce801dc.png#averageHue=%23e2dedb&clientId=u117cbb02-c405-4&from=paste&height=19&id=u5a4d688e&originHeight=27&originWidth=22&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=544&status=done&style=none&taskId=u35b16933-36f5-4a6e-9f38-0617ef05423&title=&width=15.600000381469727)是项目集合，![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680600623602-2ead0cbe-2f0a-44cd-9416-c375e1e20ae4.png#averageHue=%23e8e3dc&clientId=u117cbb02-c405-4&from=paste&height=20&id=u8403be20&originHeight=32&originWidth=42&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=683&status=done&style=none&taskId=u96c6eb16-0833-4fc1-9370-b1ed8bc6722&title=&width=26.60000228881836)是项目集合中的项目数。如果相似度![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680600778212-9acc3920-50d8-4eb4-8552-7c0d88aa246c.png#averageHue=%23eeeae5&clientId=u117cbb02-c405-4&from=paste&height=19&id=u20c67a62&originHeight=29&originWidth=289&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=3706&status=done&style=none&taskId=uf794d42b-43e9-4190-9456-f3c5125f92e&title=&width=192.1999969482422)则认为是正对，t是阈值。物品的正样本也是用类似的方法选择的。此外，阴性样本是随机选取的。<br />MMCLR[88]构造了一个视图(用户-项目图)G和一个序列视图(多行为序列)S。对于每个视图，相同用户的不同行为表示(例如$h^g_{u,b_1}$,$h^g_{u,b_2}$)被视为正对。它还最大化同一用户在不同视图的总体表示之间的MI(例如$h^g_{u}$,$h^s_{u}$)。KMCLR[98]最大化了同一用户不同行为之间的MI。此外，它还进行知识意识的对比学习。利用知识图来指导目标行为$G_{ui}^{b_t}$的用户-物品图增强。类似KGCL，首先计算每一物品的i的一致性$c_i$,然后边缘丢弃概率通过下式计算：![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1680614114241-fe7b6648-d2d3-4e89-8220-ef8f25a521aa.png#averageHue=%23f7f5f3&clientId=u527843d1-8f4c-4&from=paste&height=56&id=u21667dd7&originHeight=100&originWidth=627&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=12934&status=done&style=none&taskId=u39393819-5080-408a-ae1a-bb41c2cfdc8&title=&width=350.6000061035156)<br />$h_u$和$h_i$分别是$G_{ui}^{b_t}$中的用户和物品的表示。min_ Max(·)是Min - Max归一化函数。a和b是超参数控制$p_{ui}$的取值区间。然后采用类似KGCL的方法进行边缘丢弃。此外，KMCLR采用了节点自识别任务。<br />**社交推荐**。对于社交推荐，社交网络被用来提高推荐性能。与基于 KG 的推荐类似，视图可以基于手动设计生成。SEPT[107]基于交互数据和社交网络构建了三个图视图，包括偏好视图$G_r$、朋友视图$G_f$和共享视图$G_s$。$G_r$是用户-项目交互图。其他视图是基于两种类型的三角形图案构建的。此外，它利用三元训练tri-training[119]来预测每个视图的正样本......<br />HGCL_S[10]构造了三种类型的图：用户-项目图、用户-用户图和项目-项目图。它对相应的图执行节点自判别任务。此外，当在用户-用户图和项目-项目图中生成节点表示时，利用了元网络(Meta Network)。<br />**跨域推荐。**<br />**群体推荐。**<br />**捆绑推荐。**<br />**会话推荐。**
<a name="U0lTt"></a>
### 5.1.2C-C对比
![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681006686500-ae1ed518-9df3-4eb2-92a6-80be956a432b.png#averageHue=%23f6f4f2&clientId=u527843d1-8f4c-4&from=paste&height=37&id=u7d465eb6&originHeight=63&originWidth=440&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7635&status=done&style=none&taskId=u9b7947af-5d03-4805-8760-a703cb276a9&title=&width=256)<br />其中ci和cj是具有相似的上下文信息的上下文表示。<br />**多行为推荐：**为了捕捉不同的用户行为模式，**HMG-CR**[99]执行超元图判别任务。它首先基于超元路径为每个用户构造了不同的超元图$\{{G_{(𝑖)}^𝑢 }\}^𝐾_{𝑖=1}$。具体而言，超元路径是基于到目标行为的距离来构建的。然后通过不同的编码器生成这些超元图的表示，例如$c_u^{(i)}=f_θ^i(G_u^{(i)})$. 此外，它还采用相邻超元图表示 $(c^{(𝑖−1)}_𝑢 , c^{(𝑖)}_𝑢 )$作为负对。通过将当前超元图送到相邻超元图的编码器中来生成正样本。例如，$c^{(𝑖)}_𝑢$的正样本是$c_𝑝 = 𝑓^{𝑖−1}_𝜃(G^{(𝑖)}_𝑢)$.<br />**基于HIN的推荐：CHEST[76]**<br />**序列推荐：GCL4SR [ 115]，MISS [26 ]**
<a name="uRBBc"></a>
### 5.1.3G-G对比
![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681009471994-9eb3de25-88cd-42fa-b3fe-165e1b2ac083.png#averageHue=%23f5f3f1&clientId=u527843d1-8f4c-4&from=paste&height=38&id=uaae97e5b&originHeight=62&originWidth=440&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7721&status=done&style=none&taskId=u0d855297-4291-438b-b22b-09347014a18&title=&width=267)<br />其中g𝑖 和g𝑗 是全局表示。此外，**G-G对比通常用于顺序推荐和基于会话的推荐，**其中g表示序列或会话。<br />**序列推荐：**<br />**（i)基于数据增强：**CL4SRec[96]**,**H2SeqRec [48 ],CoSeRec [52] ,ContraRec [ 73],TiCoseRec [18],IOCRec [47 ],MCCM [77],CCL [ 5],MIC [ 58],EC4SRec [ 78];<br />**（ii)基于模型增强：**DuoRec [63],CBiT [ 20]，ContrastVAE [81 ]，CLUE [15 ]，FDSA_CL<br />**会话推荐：**<br />DHCN [ 93]，OD-Rec[ 94]，CGL [61]<br />**基于特征增强：**CFM [ 104 ]，CL4CTR [74 ]，CLCRec [86]
<a name="EdBmo"></a>
## 5.2不同尺度对比
在跨尺度对比中（如图9所示），对比是在不同尺度上进行的。此外，根据尺度，我们将这一分支方法进一步分为三个子类型：局部-上下文（L-C）对比、局部-全局（L-G）上下文-全局（C-G）对比。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681010417441-e194c720-0555-45a6-8e0a-9cb45f03661e.png#averageHue=%23f4f1ee&clientId=u527843d1-8f4c-4&from=paste&height=211&id=u025c54ec&originHeight=429&originWidth=521&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=34019&status=done&style=none&taskId=uff6b8662-0fb3-4d21-8c9d-e1281f0f03b&title=&width=256.8000183105469)
<a name="zep8U"></a>
### 5.2.1 Local-Contextual Contrasting.
![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681010495317-e581e271-d07b-424d-bdd2-a69494178211.png#averageHue=%23f5f3f0&clientId=u527843d1-8f4c-4&from=paste&height=34&id=u598a49ea&originHeight=60&originWidth=432&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7560&status=done&style=none&taskId=uca1a2169-8d7d-49c0-be5a-27ea6a4d998&title=&width=243.60000610351562)<br />**基于图的协同过滤：** 为了获取上下文信息，NCL[49]提出了一个原型对比目标。具体来说，对于每个项目/用户，正样本是其所属集群的原型，负样本是其他集群的原型。原型是簇中心的表示。此外，使用期望最大化（EM）算法学习原型对比目标。NCL还进行了跨层对比。对于每个用户/项目，从偶数层GNN输出的相应表示被视为正样本。<br /> **Sequential Recommendation. ICL [13]** <br />**Cross-domain Recommendation. SITN [66 ]**<br />**Social Recommendation: MHCN [ 108 ], SMIN [55 ]**
<a name="IGEqe"></a>
### 5.2.2 Local-Global Contrasting.
![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681010824213-1c2c4893-0317-4e7a-8861-5c63e3153795.png#averageHue=%23f5f3f1&clientId=u527843d1-8f4c-4&from=paste&height=36&id=u36e783ac&originHeight=64&originWidth=433&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7981&status=done&style=none&taskId=ucbd0be60-8c9e-47fa-aa44-41474c31489&title=&width=244.40000915527344)<br />**基于图的协同过滤：**EGLN[101]将对比放在边缘表示(即连接节点的表示的连接)和全局图表示(即所有边缘表示的平均值)之间。具体来说，g1的正样本(G1的表示)是图G1的边表示，负样本是增强图G2中的边表示。HGCL[6]构造节点类型特定的同构图以保持异构性。遵循DGI[72]，它最大化了节点表示和对应图表示之间的MI。此外，为了融合不同节点类型之间的关系，HGCL还设计了一个跨类型对比目标。对于每个节点类型对$(t_1,t_2)$，给定节点类型特定的齐次图$G^{(t_2)}$，其正样本为$G^{(t_2)}$中的节点表示，负样本为增广图$G^{(t_1)}$中的节点表示。
<a name="DdyJK"></a>
### 5.2.3 Contextual-Global Contrasting.
![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681043526907-22dac2b4-b931-491c-8eb8-76afd66007e2.png#averageHue=%23f6f4f2&clientId=u527843d1-8f4c-4&from=paste&height=37&id=ud4912ec7&originHeight=65&originWidth=433&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=7865&status=done&style=none&taskId=ud5320de8-3b5d-43f0-a789-06dba868f5e&title=&width=243.39999389648438)<br />**基于图的协同过滤：**对于每条边（i，j），BiGI[9]执行自我网络采样分别地获得以𝑖 和𝑗为中心的子图, 然后，它采用注意力机制来获得两个上下文表征。此边的上下文表示$s_{ij}$ 是的上下文表示的串联𝑖 和𝑗。具体地，g1的正样本是$G^{(1)}$中的边的上下文表示，负样本是增强图$G^{(2)}$中的边的上下文表示。MMSSL[85]生成用户的多个模态特定表示。此外，它最大化了同一用户的模态特定表示和整体表示之间的MI。特定模态表征的负样本$c^m_u$ 都是不同用户的模态特定表示$c^𝑚_{𝑢′}$和整体表示$g^𝑚_{𝑢′}$ 。<br />**Cross-domain Recommendation. C2DSR [ 8 ]**<br />**Sequential Recommendation. SSI [ 111]，S3-Rec[117]，TCPSRec[69]**
<a name="a7DVO"></a>
## 5.3总结
上图显示了不同前置任务之间的比较。<br />大多数现有的方法都使用相同的比例对比，因为只需要生成相同比例的表示。相反，跨尺度对比需要为所有不同的尺度生成相应的表示。<br />此外，由于现有的基于CL的方法通常使用共享编码器来生成表示，因此采用跨尺度对比的方法通常需要额外的模块（例如摘要函数summary function）来在生成小尺度表示之后生成大尺度表示。以基于图的推荐中的局部-全局对比为例，它需要首先学习每个节点的表示，然后聚合这些表示，使用[readout function](https://blog.csdn.net/qq_36158230/article/details/124070118)生成图表示。上下文对比也往往具有很高的复杂性，因为它需要设计相应的策略（即上下文提取）来决定数据的哪一部分来生成上下文表示。<br />此外，与通常旨在识别不同实例的同尺度对比相比，跨尺度对比侧重于建模小尺度和大尺度之间的归属关系。考虑到复杂性，在跨尺度对比中，通常从小尺度表示中选择负样本。此外，跨尺度对比可以将更多的信息引入到小尺度表示中，但这也可能引入更多的噪声，即不相关的信息。
<a name="XBb69"></a>
# 6.对比目标
如第3.1节所述，对比目标是最大化不同视图之间的互信息(MI)。具体地说，给定实例$(i,j)$的表示$(h_i,h_j)$，它们之间的MI可以表示为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681095358071-64fa4ce4-0af7-40ac-b990-5b19df39ff5a.png#averageHue=%23f5f3f2&clientId=u527843d1-8f4c-4&from=paste&height=45&id=ud919b847&originHeight=90&originWidth=960&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=16533&status=done&style=none&taskId=u21b16657-ddee-47a1-bb73-3ef9d86db2a&title=&width=481.3999938964844)<br />其中𝐾𝐿(·)是[Kullback-Leibler(KL)散度](https://zhuanlan.zhihu.com/p/438129018)。对比学习旨在最大化正对之间的MI，并最小化负配对之间的MI。此外，正对来自联合分布$P(h_i,h_j)$ 负对来自边际分布的乘积$P(h_i)P(h_j)$<br />根据是否提供互信息下界的估计，我们将对比目标分为**有界目标和无界目标**。
<a name="gMWe2"></a>
## 6.1有界对比
直接计算MI是相当困难的，有研究推导了下界来估计MI[37]，例如Donsker-Varadhan估计器$MI_{D𝑉}$[ 3, 19]，Jensen-Shannon估计器$MI_{JS}$[59]，noise-contrastive estimator (InfoNCE) $MI_{NCE}$[29, 60 ]。此外，在这三个估计量中，只有$MI_{JS}$和$MI_{NCE}$目前用于基于CL的推荐。
<a name="ibLji"></a>
### 6.1.1 Jensen-Shannon Estimator.
与DV估计器相比，Jensen Shannon（JS）估计器能够更有效地估计MI。它用Jensen-Shannon散度取代了Kullback-Leibler散度。基于此的对比损失可以定义为<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681097103426-707a5e82-57b0-476a-bfcf-a6b108d2e782.png#averageHue=%23f4f2f0&clientId=u527843d1-8f4c-4&from=paste&height=35&id=u1179b001&originHeight=64&originWidth=1022&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=13844&status=done&style=none&taskId=udb8cf101-8dfd-4115-8a55-713db579e1c&title=&width=564.4000244140625)<br />$h_i$和$h_j$从分布P中采样, $h'_j$从分布中$\widetilde P$采样。𝑝𝜔(·)是[鉴别器discriminator](https://blog.csdn.net/qq_41897800/article/details/115578867)（如前置解码器），它生成$h_i$和$h_j$的一致性得分。此外，在𝑝𝜔(·)中可能存在投影头$𝑔_𝜉(·)$，它将h𝑖映射表示到z𝑖 . 明确地，$𝑔_𝜉(·)$可以是线性映射、MLP或等角映射identical map。这个𝑝𝜔(·)可以是内积, 余弦相似度, 或者是双线性变换 .
<a name="xct6S"></a>
### 6.1.2 InfoNCE Estimator.
[InfoNCE](https://blog.csdn.net/qq_46006468/article/details/126076039) 是基于 CL 的推荐方法中采用的最流行的 MI 下界。基于它的对比损失可以表示为<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681106998193-80c5356b-1d33-4fb2-8fe5-e1e2b3e58121.png#averageHue=%23f8f7f6&clientId=ub1ea8a51-c096-4&from=paste&height=66&id=ucc925b17&originHeight=117&originWidth=1031&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=16870&status=done&style=none&taskId=u4cda0353-5816-433a-b7a7-af8c0172fff&title=&width=578.4000244140625)<br />其中K是包含N个独立同分布的随机变量的集合，随机变量均服从分布$\widetilde P$. 通常地𝑝𝜔(·)是带有温度参数𝜏的余弦相似性, 例如![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681107243542-d1f66cde-b329-4418-9752-d24d11c0fa3b.png#averageHue=%23ede9e5&clientId=ub1ea8a51-c096-4&from=paste&height=22&id=u90535985&originHeight=35&originWidth=461&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=5623&status=done&style=none&taskId=uc5970956-705f-402d-b30b-c7f57342228&title=&width=283.8000183105469)， 这也被称为NT-Xent[65]损失。<br />在实践中，InfoNCE是在尺寸为𝑁+1的小块B上计算。具体而言，对于每个在B中的实例𝑖 ，其余𝑁 实例被视为负样本。基于InfoNCE的损失可以是<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681107459152-792387e5-0569-4821-8f62-0160a44e26df.png#averageHue=%23f5f3f1&clientId=ub1ea8a51-c096-4&from=paste&height=60&id=ud5dc85fe&originHeight=106&originWidth=545&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=13243&status=done&style=none&taskId=u6b76fd4a-5257-4ca1-bffd-74f60802d3c&title=&width=307)
<a name="uTEpr"></a>
## 6.2无界对比
除了上述的下限MI估计外，还使用了一些其他目标来优化对比学习，即三重损失和BYOL损失。然而它们并没有被证明是MI的下界，因此最小化它并不能保证最大化相互信息。 
<a name="hU5ry"></a>
### 6.2.1 Triplet Loss
三重损失并没有使负对的一致性最小化，只是使正对的一致性大于负对。其定义为：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681108746226-f3f66903-2d1e-4b4c-8f89-5cd92fecf752.png#averageHue=%23f4f2f0&clientId=ub1ea8a51-c096-4&from=paste&height=35&id=u8754605b&originHeight=65&originWidth=805&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=11778&status=done&style=none&taskId=u8c7ab8b4-1dbb-4e79-b576-3a695cf39c6&title=&width=435)<br />𝜖 是边距值，$h_i$和$h_j$从分布中P中采样,$h'_j$从分布中$\widetilde P$采样。鉴别器𝑝𝜔可以通过以下方式计算一致性，$𝑝_𝜔(h_i,h_j)=sigmoid(h_i,h_j)$, 或$𝑝_𝜔(h_i,h_j)=||(h_i-h_j)||$
<a name="LdeLQ"></a>
### 6.2.2 BYOL Loss
BYOL[24]使用这个目标。它只最大化正对的一致性，不使用负样本。它的定义为:<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681109658802-3821448b-70b1-482a-901c-460349bffd77.png#averageHue=%23f4f2f0&clientId=ub1ea8a51-c096-4&from=paste&height=59&id=ub89748b9&originHeight=102&originWidth=597&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=11861&status=done&style=none&taskId=u9ada84dd-2a76-4e9f-be13-d7e5f9db531&title=&width=346.6000061035156)<br />$h_i$和$h_j$从分布中P中采样，$𝑝_𝜓(·)$is an online predictor。由于没有使用负样本来防止坍塌，因此需要进行其他设计。例如，BYOL[24]利用动量编码器，停止梯度等。
<a name="Bsx5D"></a>
## 6.3总结
![image.png](https://cdn.nlark.com/yuque/0/2023/png/29360045/1681110419406-1193285e-7ae8-46f0-9b9f-1fbc9120d88f.png#averageHue=%23f4f3f2&clientId=ub1ea8a51-c096-4&from=paste&height=189&id=udae23627&originHeight=236&originWidth=889&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=30326&status=done&style=none&taskId=u67d023a3-cf5c-4565-96a5-328d57820c9&title=&width=711.2)<br />上表显示了不同对比目标之间的比较。在所有的对比目标中，InfoNCE因其良好的性能而得到了最广泛的应用。此外，InfoNCE和JS对MI的估计都是基于下界，Poole等[62]证明InfoNCE对MI估计的方差比JS低。但是InfoNCE在训练过程中需要大量的负样本，因此需要大的批量。这导致了很高的计算和时间复杂度。相比之下，当处理规模较小时，JS可以获得更好的性能。三重损失和BYOL损耗也与大批量无关。然而，它们缺乏理论支持，即没有理论证明最大化它们就能达到互信息最大化的目标。此外，三重损失正好使得负对的一致性小于正对。因此，选择信息丰富的、难以区分的正/负样本可以带来更好的性能，而使用随机或简单的样本则会导致较差的性能。此外，三重损失对边际值的选择较为敏感，因此需要谨慎调整。**BYOL损失是最有效的**，因为它不需要负样本。然而，BYOL损失不包含Wang和Isola[79]提出的均匀性，该工作表明归一化表示应该均匀分布在单位超球上。因此，很容易遇到崩溃的问题。因此，如果使用BYOL损失，通常需要额外的设计来防止它。
<a name="vnbFg"></a>
# 7.待解决问题和未来方向
<a name="aLytN"></a>
## 7.1 View Generation
视图生成是基于CL的方法的关键组成部分。然而，与计算机视觉不同的是，在计算机视觉中，可以使用各种数据增强方法（例如，调整大小、旋转、颜色失真等），为基于CL的推荐生成视图的方法仍然没有得到很好的探索。具体而言，**大多数现有的基于CL的推荐方法仅限于随机去除一些交互或破坏交互序列的顺序。此外，这些方法通常基于直观的设计，可能不适用于下游推荐任务[109]**。因此，设计更有效的视图生成策略是一个很有前途的未来方向。通常，视图生成策略需要具有以下特征：（1）适应性，生成的视图应该适应不同的任务，因为不同的任务可能使用不同类型的数据，并需要不同的信息。（2） 效率、视图生成策略不应具有高计算或时间复杂性。此外，在训练过程中动态更新增强策略也是一个很有前途的方向。
<a name="hQAmz"></a>
## 7.2 Pretext Task
通过求解Pretext任务，该模型从下游任务的数据中获取知识。因此，提取有用的知识是一个重要问题。例如，**CGI[83]提出了一种基于信息瓶颈的方法**，该方法使表示能够捕获推荐任务的最小足够信息。然而，它是为基于图的推荐而设计的，很难应用于其他推荐任务。此外，由于不同的任务可以捕获不同的信息，因此使用多个不同的Pretext任务进行学习可以进一步提高推荐性能。还值得进一步研究如何针对特定的推荐任务自适应地组合不同的Pretext任务。<br />在对比Pretext任务中，负样本是必不可少的，但获得信息丰富的负样本是一项挑战。常用的均匀采样策略通过随机采样获得负样本，但存在假阴性。此外，简单的负样本可能会降低对比学习的性能，因为它们提供的信息很少。因此，**有效的负采样策略值得进一步研究**。一些工作[16，41]探讨了计算机视觉中的这个问题。然而，这些方法是专门为图像数据设计的，并且很难应用于推荐方法。此外，由于目前的方法需要大量的负样本，因此还需要探索有效的负样本策略。
<a name="TCNiU"></a>
## 7.3 Contrastive Objective
大多数基于CL的推荐方法都使用InfoNCE作为其目标函数，因为它简单有效。尽管已经取得了巨大的成功，但有两个问题需要进一步探讨。首先，[**InfoNCE**](https://blog.csdn.net/qq_46006468/article/details/126076039)**中相互信息的测量是基于KL散度的**。因此，它会遇到由KL发散引起的问题（例如，不对称估计和不稳定训练）。因此，需要更好的互信息测量，但一些工作[21]对这个问题进行了研究。_Fan等人[21]提出了基于2-Wasserstein距离的Wasserstein差异测量，以测量相互信息。此外，它只应用于顺序推荐，它对其他推荐任务的适用性还有待进一步探索。_其次，目前的方法使用互信息来衡量一致性。然而，互信息有几个缺点。除了难以估计之外，互信息还可能导致次优表示[71]。因此，探索一致性的替代措施，如Xu等人[97]提出的V信息，是一个很有前途的方向。
<a name="tcPbW"></a>
## 7.4 Misc.
Meeting Real-World Recommendation.<br />Learning with Advanced Techniques.Learning








